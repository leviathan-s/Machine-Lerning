# This function returns some kind of performance indexes for classifiers
# Input labels, prediction result(class and probability)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

def get_clf_eval(y_test, pred=None, pred_proba=None):
  confusion = confusion_matrix(y_test, pred)
  accuracy = accuracy_score(y_test, pred)
  precision = precision_score(y_test, pred)
  recall = recall_score(y_test, pred)
  f1 = f1_score(y_test, pred)
  roc_auc = roc_auc_score(y_test, pred_proba)
  print("Confusion Matrix!")
  print(confusion)
  print("Accuracy : ", accuracy)
  print("Precision : ", precision)
  print("Recall : ", recall)
  print("F1 : ", f1)
  print("AUC : ", roc_auc)
